version: "2.1"

services:
  #############
  # RDF Layer #
  #############
  triples-reader:
    build: ./examples
    networks:
      - spark-net
    environment:
      ### Following four examples fail:
      SPARK_APPLICATION_MAIN_CLASS: "net.sansa_stack.examples.spark.rdf.TripleReader"
      SPARK_APPLICATION_ARGS: "hdfs://namenode:8020/data/rdf.nt"
      #SPARK_APPLICATION_ARGS: "/data/rdf.nt"
    volumes:
      - ./examples/data:/data
  triple-ops:
    build: ./examples
    networks:
      - spark-net
    environment:
      SPARK_APPLICATION_MAIN_CLASS: "net.sansa_stack.examples.spark.rdf.TripleOps"
      SPARK_APPLICATION_ARGS: "hdfs://namenode:8020/data/rdf.nt"
      #SPARK_APPLICATION_ARGS: "/data/rdf.nt"
    volumes:
      - ./examples/data:/data
  triples-writer:
    build: ./examples
    networks:
      - spark-net
    environment:
      SPARK_APPLICATION_MAIN_CLASS: "net.sansa_stack.examples.spark.rdf.TripleWriter"
      #SPARK_APPLICATION_ARGS: "hdfs://namenode:8020/data/rdf.nt hdfs://namenode:8020/output_folder"
      SPARK_APPLICATION_ARGS: "/data/rdf.nt /output/output_folder"
    volumes:
      - ./examples/data:/data
      - ./output:/output
  rdf-stats:
    build: ./examples
    networks:
      - spark-net
    environment:
      SPARK_APPLICATION_MAIN_CLASS: "net.sansa_stack.examples.spark.rdf.RDFStats"
      SPARK_APPLICATION_ARGS: "/data/rdf.nt /output/output_folder"
    volumes:
      - ./examples/data:/data
      - ./output:/output
  # Fails
  pagerank:
    build: ./examples
    networks:
      - spark-net
    environment:
      SPARK_APPLICATION_MAIN_CLASS: "net.sansa_stack.examples.spark.rdf.PageRank"
      SPARK_APPLICATION_ARGS: "hdfs://namenode:8020/data/rdf.nt"
      #SPARK_APPLICATION_ARGS: "/data/rdf.nt"
    volumes:
      - ./examples/data:/data
  #####################
  # Inferencing Layer #
  #####################
  # HDFS read/write fails
  inferencing:
    build: ./examples
    networks:
      - spark-net
    environment:
      SPARK_APPLICATION_MAIN_CLASS: "net.sansa_stack.examples.spark.inference.RDFGraphInference"
      #SPARK_APPLICATION_ARGS: "hdfs://namenode:8020/data/rdf.nt hdfs://namenode:8020/output rdfs"
      SPARK_APPLICATION_ARGS: "/data/rdf.nt /output/ rdfs"
    volumes:
      - ./output:/output
      - ./examples/data:/data
  ###############
  # Query Layer #
  ###############
  # Fails
  sparklify:
    build: ./examples
    networks:
      - spark-net
    environment:
      SPARK_APPLICATION_MAIN_CLASS: "net.sansa_stack.examples.spark.query.Sparklify"
      SPARK_APPLICATION_ARGS: "hdfs://namenode:8020/data/rdf.nt"
      #SPARK_APPLICATION_ARGS: "/data/rdf.nt"
    volumes:
      - ./output:/output
      - ./examples/data:/data
  #############
  # OWL Layer #
  #############
  owl-reader-manchester:
    build: ./examples
    networks:
      - spark-net
    environment:
      SPARK_APPLICATION_MAIN_CLASS: "net.sansa_stack.examples.spark.owl.OWLReaderRDD"
      SPARK_APPLICATION_ARGS: "hdfs://namenode:8020/data/ont_manchester.owl manch"
      #SPARK_APPLICATION_ARGS: "/data/ont_manchester.owl manch"
    volumes:
      - ./examples/data:/data
  owl-reader-functional:
    build: ./examples
    networks:
      - spark-net
    environment:
      SPARK_APPLICATION_MAIN_CLASS: "net.sansa_stack.examples.spark.owl.OWLReaderRDD"
      SPARK_APPLICATION_ARGS: "hdfs://namenode:8020/data/ont_functional.owl fun"
      #SPARK_APPLICATION_ARGS: "/data/ont_functional.owl fun"
    volumes:
      - ./examples/data:/data
  owl-dataset-reader-manchester:
    build: ./examples
    networks:
      - spark-net
    environment:
      SPARK_APPLICATION_MAIN_CLASS: "net.sansa_stack.examples.spark.owl.OWLReaderDataset"
      SPARK_APPLICATION_ARGS: "hdfs://namenode:8020/data/ont_manchester.owl manch"
      #SPARK_APPLICATION_ARGS: "/data/ont_manchester.owl manch"
    volumes:
      - ./examples/data:/data
  owl-dataset-reader-functional:
    build: ./examples
    networks:
      - spark-net
    environment:
      SPARK_APPLICATION_MAIN_CLASS: "net.sansa_stack.examples.spark.owl.OWLReaderDataset"
      SPARK_APPLICATION_ARGS: "hdfs://namenode:8020/data/ont_functional.owl fun"
      #SPARK_APPLICATION_ARGS: "/data/ont_functional.owl fun"
    volumes:
      - ./examples/data:/data
  ############
  # ML Layer #
  ############
  # Does not work with HDFS, does not write to output_file
  clustering:
    build: ./examples
    networks:
      - spark-net
    environment:
      SPARK_APPLICATION_MAIN_CLASS: "net.sansa_stack.examples.spark.ml.clustering.RDFByModularityClusteringExample"
      #SPARK_APPLICATION_ARGS: "hdfs://namenode:8020/data/Clustering_sampledata.nt hdfs://namenode:8020/output_file 10"
      SPARK_APPLICATION_ARGS: "/data/Clustering_sampledata.nt /output/output_file 10"
    volumes:
      - ./output:/output
      - ./examples/data:/data
  # Fails
  rule-mining:
    build: ./examples
    networks:
      - spark-net
    environment:
      SPARK_APPLICATION_MAIN_CLASS: "net.sansa_stack.examples.spark.ml.mining.MineRules"
      SPARK_APPLICATION_ARGS: "hdfs://namenode:8020/data/resourcesMineRules_sampledata.tsv hdfs://namenode:8020/output/output_folder"
      #SPARK_APPLICATION_ARGS: "/data/resourcesMineRules_sampledata.tsv /output/output_folder"
    volumes:
      - ./output:/output
      - ./examples/data:/data
    networks:
      - spark-net

networks:
  spark-net:
    external:
      name: spark-net
