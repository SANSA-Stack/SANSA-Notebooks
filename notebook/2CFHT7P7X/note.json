{
  "paragraphs": [
    {
      "title": "Sparqlify example",
      "text": "import org.apache.jena.riot.Lang\nimport net.sansa_stack.rdf.spark.io._\nimport net.sansa_stack.query.spark.query._\n\nval input \u003d \"hdfs://namenode:8020/data/rdf.nt\"\nval lang \u003d Lang.NTRIPLES\n\nval triples \u003d spark.rdf(lang)(input)\n\nval sparqlQuery \u003d \"\"\"SELECT ?s ?p ?o\n                            WHERE {?s ?p ?o }\n                     LIMIT 10\"\"\"\n    \nval result \u003d triples.sparql(sparqlQuery)\n        \nz.show(result)",
      "user": "anonymous",
      "dateUpdated": "2018-12-17 12:32:55.176",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {
          "1": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "C_3": "string",
                      "C_4": "string",
                      "C_5": "string",
                      "C_10": "string",
                      "C_6": "string",
                      "C_7": "string",
                      "C_8": "string",
                      "C_9": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            },
            "helium": {}
          }
        },
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "tableHide": false,
        "title": true,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import org.apache.jena.riot.Lang\nimport net.sansa_stack.rdf.spark.io._\nimport net.sansa_stack.query.spark.query._\ninput: String \u003d hdfs://namenode:8020/data/rdf.nt\nlang: org.apache.jena.riot.Lang \u003d Lang:N-Triples\ntriples: org.apache.spark.rdd.RDD[org.apache.jena.graph.Triple] \u003d MapPartitionsRDD[2] at mapPartitions at NTripleReader.scala:140\nsparqlQuery: String \u003d\nSELECT ?s ?p ?o\n                            WHERE {?s ?p ?o }\n                     LIMIT 10\nresult: org.apache.spark.sql.DataFrame \u003d [C_3: string, C_4: string ... 6 more fields]\n"
          },
          {
            "type": "TABLE",
            "data": "C_3\tC_4\tC_5\tC_10\tC_6\tC_7\tC_8\tC_9\nhttp://commons.dbpedia.org/property/artist\tnull\tJean Broc\thttp://commons.dbpedia.org/resource/File:The_Death_of_Hyacinthos.gif\ten\tnull\tnull\tnull\nhttp://commons.dbpedia.org/property/date\tnull\tnull\thttp://commons.dbpedia.org/resource/File:Buswachten.jpg\tnull\tnull\t2004-07-22\tnull\nhttp://commons.dbpedia.org/property/date\tnull\tnull\thttp://commons.dbpedia.org/resource/File:Groninger-museum.jpg\tnull\tnull\t2004-08-26\tnull\nhttp://commons.dbpedia.org/property/date\tnull\tnull\thttp://commons.dbpedia.org/resource/File:StationAssen3.jpg\tnull\tnull\t2004-07-22\tnull\nhttp://commons.dbpedia.org/property/date\tnull\tnull\thttp://commons.dbpedia.org/resource/File:De_Slegte,_Groningen.jpg\tnull\tnull\t2004-08-26\tnull\nhttp://commons.dbpedia.org/property/date\tnull\tnull\thttp://commons.dbpedia.org/resource/File:Paddestoel_003.jpg\tnull\tnull\t2004-08-20\tnull\nhttp://commons.dbpedia.org/property/date\tnull\tnull\thttp://commons.dbpedia.org/resource/File:BordUtrecht.jpg\tnull\tnull\t2004-07-22\tnull\nhttp://commons.dbpedia.org/property/date\tnull\tnull\thttp://commons.dbpedia.org/resource/File:Paddestoel_002.jpg\tnull\tnull\t2004-08-20\tnull\nhttp://commons.dbpedia.org/property/date\tnull\tnull\thttp://commons.dbpedia.org/resource/File:Groningen_003.jpg\tnull\tnull\t2004-08-26\tnull\nhttp://commons.dbpedia.org/property/date\tnull\tnull\thttp://commons.dbpedia.org/resource/File:StationAssen2.jpg\tnull\tnull\t2004-07-22\tnull\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1504609209863_-361690439",
      "id": "20170905-110009_242595472",
      "dateCreated": "2017-09-05 11:00:09.000",
      "dateStarted": "2018-12-17 12:32:55.217",
      "dateFinished": "2018-12-17 12:33:40.368",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "DataLake (CSV) example",
      "text": "import net.sansa_stack.query.spark.query._\n\nval queryFile \u003d \"hdfs://namenode:8020/data/datalake/queries/Q1.sparql\"\nval mappingsFile  \u003d \"hdfs://namenode:8020/data/datalake/config\"\nval configFile \u003d \"hdfs://namenode:8020/data/datalake/mappings.ttl\"\n\n\nval result \u003d spark.sparqlDL(queryFile, mappingsFile, configFile)\n\nz.show(result)",
      "user": "anonymous",
      "dateUpdated": "2018-12-20 14:45:41.748",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "import net.sansa_stack.query.spark.query._\nqueryFile: String \u003d hdfs://namenode:8020/data/datalake/queries/Q1.sparql\nmappingsFile: String \u003d hdfs://namenode:8020/data/datalake/config\nconfigFile: String \u003d hdfs://namenode:8020/data/datalake/mappings.ttl\n\n/*******************************************************************/\n/*                         QUERY ANALYSIS                          */\n/*******************************************************************/\nERROR: One of input files ins\u0027t found.\nresult: org.apache.spark.sql.DataFrame \u003d null\njava.lang.NullPointerException\n  at org.apache.zeppelin.interpreter.BaseZeppelinContext.show(BaseZeppelinContext.java:241)\n  at org.apache.zeppelin.interpreter.BaseZeppelinContext.show(BaseZeppelinContext.java:224)\n  ... 68 elided\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1545316466313_1169067992",
      "id": "20181220-143426_1689489474",
      "dateCreated": "2018-12-20 14:34:26.314",
      "dateStarted": "2018-12-20 14:45:41.774",
      "dateFinished": "2018-12-20 14:45:43.525",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Sparqlify Example with SPARQL Endpoint",
      "text": "\n\nimport scala.collection.mutable\n\nimport org.apache.jena.riot.Lang\nimport net.sansa_stack.rdf.spark.io._\nimport net.sansa_stack.query.spark.query._\nimport net.sansa_stack.query.spark.sparqlify.QueryExecutionFactorySparqlifySpark\nimport net.sansa_stack.query.spark.sparqlify.SparqlifyUtils3\nimport org.aksw.jena_sparql_api.server.utils.FactoryBeanSparqlServer\n\n\nval input \u003d \"hdfs://namenode:8020/data/rdf.nt\"\nval triples \u003d  spark.rdf(Lang.NTRIPLES)(input)\nval partitions \u003d triples.partitionGraph()\n\nval rewriter \u003d SparqlifyUtils3.createSparqlSqlRewriter(spark, )\n    \nval port \u003d 7531\n    \nval qef \u003d new QueryExecutionFactorySparqlifySpark(spark, rewriter)\nval server \u003d FactoryBeanSparqlServer.newInstance.setSparqlServiceFactory(qef).setPort(port).create()\n\n\nserver.join()",
      "user": "anonymous",
      "dateUpdated": "2018-12-17 12:35:28.461",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true,
        "fontSize": 9.0
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1511348574973_-104865431",
      "id": "20171122-110254_218685772",
      "dateCreated": "2017-11-22 11:02:54.000",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Query",
  "id": "2CFHT7P7X",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {
    "spark:shared_process": []
  },
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}